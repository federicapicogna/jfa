---
title: "Evaluating audit samples with partial misstatements"
author: Koen Derks
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
bibliography: references.bib
csl: apa.csl
vignette: >
  %\VignetteIndexEntry{Evaluating audit samples with partial misstatements}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteDepends{jfa}
  %\VignetteKeywords{audit, evaluation, jfa}
  %\VignettePackage{jfa}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(jfa)
```

## Introduction

This vignette illustrates the efficient evaluation of samples with partial
misstatements using the `evaluation()` function from the **jfa** package.

<p align='center'><img src='evaluation.png' alt='evaluation' width='100%'></p>

In auditing, the objective of evaluation is typically to estimate the
misstatement in the population based on a sample or to test the misstatement
against a critical upper limit, known as performance materiality.

## Modeling partial misstatements

Partial misstatements occur when there is only a partial discrepancy between the
true value of an item in the sample and its recorded value. From a data
perspective, this implies that the misstatements in the sample are not binary
(i.e., 0 or 1) but often lie between 0 and 1. In practice, this means that the
usual methods for evaluating audit samples do not suffice.

To illustrate how auditors can adequately deal with this type of misstatements,
we examine a realistic sample from a financial audit using the `allowances` data
set included in the package. For clarity, we perform some data pre-processing to
arrive at the population for our example. In this case, the performance
materiality (i.e., the maximum tolerable misstatement) for the population is set
to ten percent.

```{r}
data("allowances")
population <- allowances
population <- population[population[["bookValue"]] > 0, ]
population <- population[!is.na(population[["auditValue"]]), ]
population <- population[population[["auditValue"]] > 0, c(1, 3, 4)]
head(population)
```

To decide whether the misstatement in the population is lower than the
performance materiality of ten percent, a sample of 50 items is selected from
the population of 1177 items. In this case, the sample is selected using a fixed
interval sampling method in which the items in the population are randomized
before selection.

```{r}
set.seed(1)
sample <- selection(
  data = population, size = 50,
  method = "interval", units = "values", values = "bookValue",
  randomize = TRUE
)$sample
```

After inspecting the items in the sample, each item is annotated with its
recorded (i.e., book) value and its true (i.e., audit) value. When evaluating
partial misstatements, auditors often calculate the 'taint' $t$ of each item,
which is defined as the proportional misstatement in the item:

$$t = \frac{\text{Book value} \, -  \, \text{Audit value}}{\text{Book value}}.$$

For instance, an item that is booked for $1,000 but has an audit value of $500
has a taint of $t = 0.5$. On the other hand, if an item does not contain any
misstatement, it has a taint of $t = 0$.

As is often the case in practice, this audit sample contains many taints that
are zero, and only some taints that are greater than zero. The table below shows
this distribution of taints.

```{r}
sample[["difference"]] <- sample[["bookValue"]] - sample[["auditValue"]]
sample[["taint"]] <- sample[["difference"]] / sample[["bookValue"]]
table(round(sample[["taint"]], 3))
```

Typically, techniques for evaluating audit samples overlook the prevalence of
many zeros in the data. Yet, considering the abundance of zeros while modeling
the misstatement in the population can enhance the auditor's efficiency. In the
following sections, we demonstrate two approaches that can be used to deal with
partial misstatements and show how they improve the auditor's efficiency.

## Classical approaches

Classical (i.e., frequentist) methods solely look to the data for estimating the
parameters in a statistical model via maximum likelihood estimation. This
methodology is widely adopted in auditing, and therefore we will discuss it
first in this vignette.

### Binomial likelihood

The simplest way to analyze partial misstatements is to aggregate them and use
the sum of proportional misstatements (i.e., the total taint) to project to the
population. Under the hood, this approach employs a binomial likelihood to
estimate the misstatement in the population $\theta$. The method uses the sum of
the taints, denoted as $k = \sum_{i=0}^n t_i$, as the number of errors and
therefore does not take into account the fact that the data contain many zeros.

$$k \sim \text{Binomial}(n, \theta)$$

While aggregating the taints in this manner may not adhere to a strictly 'clean'
modeling approach, as the binomial likelihood is only defined for binary data
representing complete misstatements, it proves to be effective in estimating the
misstatement [@broeze_2006, Chapter 4.3]. Despite its somewhat unconventional
nature, the analytical feasibility of this approach makes it easy to use and
therefore it is commonly applied in practice.

For the classical binomial likelihood, aggregating the taints can be done using
`method = "binomial"` in the `evaluation()` function. Using maximum likelihood
estimation, $\theta = \frac{\sum t}{n} = \frac{4.2294}{50} = 0.084588$.

```{r}
eval_binom <- evaluation(
  method = "binomial", data = sample, materiality = 0.1,
  values = "bookValue", values.audit = "auditValue"
)
print(eval_binom)
```

As shown in the output, the most likely misstatement is estimated to be 8.46
percent, with a 95 percent upper bound of 17.96 percent. Note that this approach
might be effective (i.e., estimate the misstatement well) but not not very
efficient (i.e., has a relatively high upper bound). That is because it does not
take into account the information in the distribution of the taints.

### Stringer bound

The Stringer bound is a frequentist method to improve efficiency by taking into
account the differences between the magnitude of the taints [@stringer_1963;
@bickel_1992]. The bound is a variant of the binomial distribution, but
considers the non-binary nature of the taints. The Stringer upper bound on the
population misstatement is given by

$$p(0, 1 - \alpha) + \sum_{i=1}^k [p(i, 1 - \alpha) - p(i - 1, 1 - \alpha)] \times t_i.$$

In the formula above, $p(i; 1 - \alpha)$ is the $1 - \alpha$ upper limit for at
most $i$ misstatements in $n$ items according to the binomial distribution
[@clopper_1934]. This is equal to the $1 - \alpha$ percentile of a
beta($1 + i$, $n - i$) distribution [@pearson_1948]. When calculating the
Stringer bound, the taints are placed in descending order in the formula as a
form of conservatism.

In `jfa`, the Stringer bound can be applied using `method = "stringer"` in the
`evaluation()` function. Using maximum likelihood estimation,
$\theta = \frac{\sum t}{n} = \frac{4.2294}{50} = 0.084588$.

```{r}
eval_stringer <- evaluation(
  method = "stringer", data = sample, materiality = 0.1,
  values = "bookValue", values.audit = "auditValue"
)
print(eval_stringer)
```

As shown in the output, the most likely misstatement is estimated to be 8.46
percent, with a 95 percent upper bound of 17.23 percent. Since the upper bound of
the Stringer method is (slightly) lower than that of the binomial likelihood,
the Stringer bound is more efficient.

### Hurdle beta model

Efficiency can be further improved by explicitly modeling the probability of a
taint being zero (i.e., zero-inflation). This is a more realistic method
because, in practice, most taints are zero. In in the context of a zero-inflated
Poisson model (i.e., `method = inflated.poisson`), the idea is to incorporate
extra zeros into the zeros already present in the Poisson distribution. However,
this idea does not directly apply to a "zero-inflated beta" model. Since beta
regression cannot accommodate zeros, there are no zeros to inflate. An
appropriate name for this model is therefore a hurdle (i.e., two-component) beta
model. This terminology reflects the idea that the model has to overcome the
hurdle of zero values which are not inherently part of the beta distribution.

$$
t =
\begin{cases}
    0 & \text{with probability}\, 1 - p\\
    \text{Beta}(\phi \nu,\, (1 - \phi) \nu) & \text{with probability}\, p
\end{cases}
$$

Here, $p$ is the probability of a non-zero taint occurring, $\phi$ is the
average non-zero taint and $\nu$ is the concentration of the taints. The average 
misstatement in the population is $\theta = p \times \phi$. In `jfa`, this
hurdle beta model can be fitted using `method = "hurdle.beta"` in the
`evaluation()` function. To estimate the parameters in this model using the
maximum likelihood, we use the default option `prior = FALSE`. Using maximum 
likelihood estimation, $p = \frac{n_t}{n} = \frac{12}{50} = 0.24$, where $n_t$
is the number of non-zero taints. Furthermore,
$\phi = \frac{\sum t}{n_t} = \frac{4.2294}{12} = 0.35245$. Hence, the most
likely misstatement is estimated as $\theta = p \times \phi = 0.084588$ (results
can differ slightly due to optimization). The upper bound cannot be derived
analytically and has to be determined by drawing samples from the fitted model.
Hence, it is recommended to call `set.seed()` to make the results reproducible.

```{r}
set.seed(1)
eval_hurdle <- evaluation(
  method = "hurdle.beta", data = sample, materiality = 0.1,
  values = "bookValue", values.audit = "auditValue"
)
print(eval_hurdle)
```

As shown in the output, the most likely misstatement is estimated to be around
8.5 percent, with a 95 percent upper bound of around 14.44 percent. Since the
upper bound of the hurdle beta model is lower than that of the Stringer bound,
the hurdle beta model is more efficient.

## Bayesian approaches

In the Bayesian framework, the auditor defines a prior distribution for the
parameters in the model. This approach offers a notable advantage for models
dealing with partial misstatement, as the prior distribution has a regularizing
effect, reducing the amount of data required for reliable inferences. More
specifically, frequentist models cannot be optimized when there are no non-zero
taints in the sample. Additionally, the prior distribution enables auditors to
integrate pre-existing information about the misstatement into the statistical
analysis, thereby increasing efficiency when the auditor has pre-existing
information about the misstatement.

### Beta distribution 

The prior distribution we typically assign in the binomial model is the beta
distribution. Just as we handle taints in the binomial likelihood, they can also
be aggregated given the prior distribution. The statistical model is:

$$
\begin{align}
  k &\sim \text{Binomial}(n, \theta)\\
  \theta &\sim \text{Beta}(\alpha, \, \beta)
\end{align}
$$

Given the data $n$ and $k = \sum t$, the posterior distribution for the default
beta(1, 1) prior distribution (`prior = TRUE`) can be derived analytically and
is

$$\text{Beta}(\alpha = 1 + \sum t, \, \beta = 1 + n - \sum t).$$

For the binomial likelihood, this Bayesian model can be applied in the
`evaluation()` function using `method = "binomial"` in comination with
`prior = TRUE`. However, the input for the `prior` argument can also be an
object created by the `auditPrior()` function.

```{r}
eval_beta <- evaluation(
  method = "binomial", data = sample, materiality = 0.1,
  values = "bookValue", values.audit = "auditValue",
  prior = TRUE
)
print(eval_beta)
```

As shown in the output, the most likely misstatement is estimated to be 8.46
percent, with a 95 percent upper bound of 17.63 percent. The prior and posterior
distribution can be visualized via the `plot(..., type = "posterior")` command.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(eval_beta, type = "posterior")
```

### Hurdle beta model

It is also possible to fit a Bayesian variant of the hurdle beta model. This
entails applying prior distributions for the parameters $p$, $\phi$, and $\nu$.
The prior distributions used by **jfa** for the Bayesian hurdle beta model are:

$$
\begin{align}
  p &\sim \text{Beta}(\alpha, \, \beta)\\
  \phi &\sim \text{Beta}(1, \, 1)\\
  \nu &\sim \text{Pareto}(1, \, 1.5)
\end{align}
$$

This Bayesian hurdle beta model can be applied using `method = "hurdle.beta"` in
combination with `prior = TRUE` (or an object created by the `auditPrior()`
function) in the `evaluation()` function. In this case, the posterior
distribution cannot be determined analytically and must be determined using MCMC
sampling, which is why it is recommended to call `set.seed()` before computing
the results.

```{r}
set.seed(1)
eval_hurdle_bayes <- evaluation(
  method = "hurdle.beta", data = sample, materiality = 0.1,
  values = "bookValue", values.audit = "auditValue",
  prior = TRUE
)
print(eval_hurdle_bayes)
```

As shown in the output, the most likely misstatement is estimated to be around
8 percent, with a 95 percent upper bound of around 14 percent. The prior and
posterior distribution can be visualized using the `plot()` function.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(eval_hurdle_bayes, type = "posterior")
```

## References
<div id="refs"></div>
