---
title: "Evaluating audit samples with partial misstatements"
author: Koen Derks
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{Evaluating audit samples with partial misstatements}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteDepends{jfa}
  %\VignetteKeywords{audit, evaluation, jfa}
  %\VignettePackage{jfa}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(jfa)
```

## Introduction

This vignette illustrates the efficient evaluation of samples with partial
misstatements using the `evaluation()` function from the **jfa** package.

<p align='center'><img src='evaluation.png' alt='evaluation' width='100%'></p>

In auditing, the objective of evaluation is typically to estimate the
misstatement in the population based on a sample or to test the misstatement
against a critical upper limit, known as performance materiality.

## Modeling partial misstatements

Partial misstatements occur when there is only a partial discrepancy between the
true value of an item in the sample and its recorded value. From a data
perspective, this implies that misstatements are often non-binary. However,
there is usually a large number of correct items in the population.

As an example, we examine a realistic sample from a financial audit using the
`allowances` data set included in the package. For clarity, we perform some data
pre-processing to arrive at an example population.

```{r}
data("allowances")
population <- allowances
population <- population[population[["bookValue"]] > 0, ]
population <- population[!is.na(population[["auditValue"]]), ]
population <- population[population[["auditValue"]] > 0, c(1, 3, 4)]
head(population)
```

To decide whether the misstatement in the population is lower than the
performance materiality of ten percent, a sample of 50 items is selected from the
population, each consisting of a book value and a true value. In this case, the
sample is selected using a fixed interval sampling method in which the items in
the population are randomized before selection.

```{r}
set.seed(1)
sample <- selection(
  data = population, size = 50,
  method = "interval", units = "values", values = "bookValue",
  randomize = TRUE
)$sample
```

When evaluating partial misstatements, auditors often calculate the 'taint' $t$
of each item, which is defined as the proportional misstatment in the item: 
$t = \frac{\text{Book value} - \text{Audit value}}{\text{Book value}}$. For
instance, an item that is booked for $1,000 but has an audit value of $500,
consequently has a taint of $t = 0.5$. On the other hand, if an item does not
contain misstatement, its taint is $t = 0$. As is often the case in practice,
this audit sample contains many taints that are zero, and only some taints that
are greater than zero. The table below shows this distribution of taints.

```{r}
sample[["difference"]] <- sample[["bookValue"]] - sample[["auditValue"]]
sample[["taint"]] <- sample[["difference"]] / sample[["bookValue"]]
table(round(sample[["taint"]], 3))
```

Normally, techniques for assessing audit samples overlook the prevalence of
zeros in the data. Yet, considering the abundance of zeros in the data during
the modeling of misstatements in the population can enhance efficiency. In the
following sections, we demonstrate two approaches that can be used to deal with
partial misstatements.

### Classical approaches

Traditional (i.e., frequentist) methods depend on the data for estimating
parameters in a statistical model through maximum likelihood estimation. This
methodology is widely adopted in auditing, and therefore we will discuss it
first in this vignette.

#### Binomial likelihood

The simplest way to analyze partial misstatements is to aggregate them and use
the sum of partial misstatements (i.e., the total taint) to project to the
population. Under the hood, this employs a binomial likelihood fitted with the
sum of the taints, denoted as $k = \sum_{i=0}^n t_i$. Note that this approach
does not yet take into account the abundance of zeros in the data.

While aggregating the taints may not adhere to a strictly 'clean' modeling
approach, as the binomial likelihood is only defined for binary data
representing complete misstatements, it proves to be effective in estimating the
misstatement (Broeze, 2006, Chapter 4.3). Despite its somewhat unconventional
nature, the analytical feasibility of this approach makes it easy to use and
therefore commonly applied.

For the classical binomial likelihood, aggregating the taints can be done using
`method = "binomial"`. 

```{r}
eval_binom <- evaluation(
  method = "binomial", data = sample, materiality = 0.1,
  values = "bookValue", values.audit = "auditValue"
)
print(eval_binom)
```

As shown in the output, the most likely misstatement is estimated to be 8.46
percent, with a 95 percent upper bound of 17.96 percent. Note that this approach
might be effective (i.e., estimate the misstatement well) but not not very
efficient (i.e., has a relatively high upper bound). That is because it does not
take into account the information in the distribution of the taints.

#### Stringer bound

The Stringer bound is a frequentist method to improve efficiency by taking into
account the differences between the magnitude of the taints (Stringer, 1963;
Bickel, 1992). The bound is a variant of the binomial distribution, but
considers the non-binary nature of the taints. The Stringer upper bound on the
population misstatement is given by

$$p(0, 1 - \alpha) + \sum_{i=1}^k [p(i, 1 - \alpha) - p(i - 1, 1 - \alpha)] \times t_i.$$

In the formula above, $p(i; 1 - \alpha)$ is the $1 - \alpha$ upper limit for at
most $i$ misstatements in $n$ items according to the binomial distribution
(Clopper and Pearson, 1934). This is equal to the $1 - \alpha$ percentile of a
beta($1 + i$, $n - i$) distribution (Pearson, 1934). When calculating the
Stringer bound, the taints are placed in descending order in the formula as a
form of conservatism.

In `jfa`, the Stringer bound can be applied using `method = "stringer"`.

```{r}
eval_stringer <- evaluation(
  method = "stringer", data = sample, materiality = 0.1,
  values = "bookValue", values.audit = "auditValue"
)
print(eval_stringer)
```

As shown in the output, the most likely misstatement is estimated to be 8.46
percent, with a 95 percent upper bound of 17.23 percent. Since the upper bound of
the Stringer method is (slightly) lower than that of the binomial likelihood,
the Stringer bound is more efficient.

#### Hurdle beta model

Efficiency can be further improved by explicitly modeling the probability of a
taint being zero (i.e., zero-inflation). This is a more realistic method
because, in practice, most taints are zero. In in the context of a zero-inflated
Poisson model (i.e., `method = inflated.poisson`), the idea is to incorporate
extra zeros into the zeros already present in the Poisson distribution. However,
this idea does not directly apply to a "zero-inflated beta" model. Since beta
regression cannot accommodate zeros, there are no zeros to inflate. An
appropriate name for this model is therefore a hurdle (i.e., two-component) beta
model. This terminology reflects the idea that the model has to overcome the
hurdle of zero values which are not inherently part of the beta distribution.

In `jfa`, the hurdle beta model can be fitted using `method = "hurdle.beta"`.
Note that this requires specifying the number of items (`N.items`) and the
number of monetary units (`N.units`) in the population.

```{r}
set.seed(1)
eval_hurdle <- evaluation(
  method = "hurdle.beta", data = sample, materiality = 0.1,
  values = "bookValue", values.audit = "auditValue",
  N.items = nrow(population), N.units = sum(population$bookValue)
)
print(eval_hurdle)
```

As shown in the output, the most likely misstatement is estimated to be around
7.8 percent, with a 95 percent upper bound of around 14.44 percent. Since the
upper bound of the hurdle beta model is lower than that of the Stringer
bound, the hurdle beta model is more efficient.

### Bayesian approaches

Within the Bayesian framework, we define a prior distribution for the parameters
in the model. This approach offers a notable advantage for models dealing with
partial misstatement, as the prior distribution exerts a regularizing influence,
reducing the amount of data required for reliable inferences. Additionally, the
prior distribution enables auditors to integrate pre-existing information about
the misstatement into the statistical analysis.

#### Beta distribution 

The Bayesian equivalent to the binomial likelihood is represented by the beta
distribution. Just as we handle taints in the binomial likelihood, they can also
be aggregated and examined utilizing a beta distribution. Given that we start
with the default beta(1, 1) prior (`prior = TRUE`), the posterior distribution
is

$$\text{Beta}(\alpha = 1 + \sum t, \beta = 1 + n - \sum t).$$

For the binomial likelihood, the Bayesian model can be applied using
`method = "binomial"` in comination with `prior = TRUE`. As usual, `prior` can
also be an object created by the `auditPrior()` function.

```{r}
eval_beta <- evaluation(
  method = "binomial", data = sample, materiality = 0.1,
  values = "bookValue", values.audit = "auditValue",
  prior = TRUE
)
print(eval_beta)
```

As shown in the output, the most likely misstatement is estimated to be 8.46
percent, with a 95 percent upper bound of 17.63 percent. The prior and posterior
distribution can be visualized via the `plot(..., type = "posterior")` function.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(eval_beta, type = "posterior")
```

#### Hurdle beta model

It is also possible to fit a Bayesian variant of the hurlde beta model. This can
be done using `method = "hurdle.beta"` in comination with `prior = TRUE` (or an
object created by the `auditPrior()` function).

```{r}
set.seed(1)
eval_hurdle_bayes <- evaluation(
  method = "hurdle.beta", data = sample, materiality = 0.1,
  values = "bookValue", values.audit = "auditValue",
  N.items = nrow(population), N.units = sum(population$bookValue),
  prior = TRUE
)
print(eval_hurdle_bayes)
```

As shown in the output, the most likely misstatement is estimated to be around
8.4 percent, with a 95 percent upper bound of around 14.5 percent. The prior and
posterior distribution can be visualized using the `plot()` function.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(eval_hurdle_bayes, type = "posterior")
```

# References

- Bickel, P. J. (1992). Inference and Auditing: The Stringer Bound. *International Statistical Review / Revue Internationale de Statistique*, 60(2), 197-209. - [View online](https://www.jstor.org/stable/1403650)
- Broeze, G. B. (2006). *Validation of Risk Assessment in Auditing*. PhD-Thesis, Vrije Universiteit Amsterdam. Limperg Instituut. - [View online](https://research.vu.nl/ws/portalfiles/portal/42174612/complete+dissertation.pdf)
- Clopper, C. J., & Pearson, E. S. (1934). The use of confidence or fiducial limits illustrated in the case of the binomial. *Biometrika*, 26(4), 404-413. - [View online](https://doi.org/10.2307/2331986)
- Pearson, K. (1934). *Tables of the Incomplete Beta Function*, London: Biometrika Office.
- Stringer, K. W. (1963). Practical aspects of statistical sampling in auditing. *Proceedings of Business and Economic Statistics Section*, American Statistical Association.
