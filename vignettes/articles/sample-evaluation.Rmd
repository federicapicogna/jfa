---
title: Evaluating statistical audit samples
author: Koen Derks
output: 
  html_document:
    toc: true
    toc_depth: 3
bibliography: references.bib
csl: apa.csl
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(jfa)
```

## Introduction

Welcome to the 'Evaluating statistical audit samples' vignette of the **jfa**
package. This page demonstrates how to evaluate the misstatement in an audit
sample using the `evaluation()` function in package.

<p align='center'><img src='evaluation.png' alt='evaluation' width='100%'></p>

In auditing, the objective of evaluation is typically 1) to estimate the
misstatement in the population based on a sample or 2) to test the misstatement
against a critical upper limit, known as performance materiality.

## Required information

Firstly, to evaluate an audit sample using the `evaluation()` function, the
sample data must be available in one of two formats:

- **Summary statistics:** This includes (a vector of) the number of items (`n`),
  (a vector of) the sum of misstatements/taints (`x`) and optionally (a vector
  of) the number of units in the population (`N.units`).
- **Data:** A `data.frame` that contains a numeric column with book values
  (`values)`, a numeric column with audit (i.e., true) values (`values.audit`),
  and optionally a factor column indicating stratum membership (`strata`).

By default, `evaluation()` estimates the population misstatement and returns a
point estimate as well as a confidence/credible interval around this estimate,
expressed as a percentage (`conf.level` $\cdot$ 100). However, in audit
sampling, the population is typically subject to a certain maximum tolerable
misstatement defined by the performance materiality $\theta_{max}$. You can
provide the performance materiality to the `evaluation()` function as a fraction
using the `materiality` argument. In addition to the default estimation,
specifying a value for `materiality` triggers the comparison of two competing
hypotheses. The hypotheses being compared depend on the input for the
`alternative` argument.

* `alternative = "less"` (default): $H_1:\theta<\theta_{max}$ versus $H_0:\theta\geq\theta_{max}$
* `alternative = "greater"`: $H_1:\theta>\theta_{max}$ versus $H_0:\theta\leq\theta_{max}$
* `alternative = "two.sided"`: $H_1:\theta \neq\theta_{max}$ versus $H_0:\theta=\theta_{max}$

Once the auditor has established the materiality (if applicable), they must make
a decision on whether to stratify the population. Stratification is the process
of dividing the population into smaller subgroups that contain similar items,
referred to as strata, and selecting a sample from each stratum. In the
following sections, we will demonstrate how to evaluate statistical audit
samples, both stratified and non-stratified.

## Evaluation using summary statistics

We first consider the scenario where the auditor does not have access to the
sample data and wants to perform inference about the misstatement using summary
statistics from the sample.

### Non-stratified samples

In a non-stratified sampling approach, the auditor does not divide the population
into different strata. This approach might be suitable when the auditor is
auditing the general ledger of a small business and has substantiated that the
population comprises homogeneous items, such as all items being employment
contracts subject to a shared ensemble of control systems.

#### Classical approach

Classical hypothesis testing employs the *p*-value to determine whether to
reject the null hypothesis of material misstatement $H_0$. For instance,
let's assume an auditor aims to confirm if the population contains less than
five percent misstatement. This suggests the hypotheses $H_1$: $\theta <$ 0.05
and $H_0$: $\theta \geq$ 0.05. The auditor selects a sample of $n$ = 100 items,
with $k$ = 1 item containing a misstatement. They establish the significance
level for the *p*-value (i.e., the sampling risk) at $\alpha$ = 0.05, indicating
that a *p*-value below 0.05 will suffice to reject the null hypothesis. The
following command evaluates the sample using a classical non-stratified
evaluation method [@stewart_2012].

```{r}
evaluation(materiality = 0.05, x = 1, n = 100)
```

The output indicates that the most likely misstatement in the population is
estimated to be $\frac{k}{n}$ = $\frac{1}{100}$ = 0.01, or 1 percent, and the
95 percent (one-sided) confidence interval spans from 0 percent to 4.74 percent.
It also reveals that the *p*-value is below 0.05, suggesting that the null
hypothesis should be rejected. Consequently, the auditor can infer that the
sample provides sufficient evidence to conclude with a reasonable degree of
certainty that the population does not contain material misstatement.

#### Bayesian approach

Bayesian hypothesis testing employs the Bayes factor, either $BF_{10}$ or
$BF_{01}$, to quantify the evidence that the sample provides in support of
either of the two hypotheses $H_1$ or $H_0$ [@derks_2021b]. For instance, a
Bayes factor value of $BF_{10}$ = 10 (provided by the `evaluation()` function)
can be interpreted as the data being 10 times more likely under the hypothesis
of tolerable misstatement $H_1$ than under the hypothesis of material
misstatement $H_0$. A value of $BF_{10} >$ 1 indicates evidence in favor of
$H_1$ and opposing $H_0$, while a value of $BF_{10} <$ 1 indicates evidence
supporting $H_0$ and contradicting $H_1$. The `evaluation()` function returns
the value for $BF_{10}$, but $BF_{01}$ can be calculated as $\frac{1}{BF_{10}}$.

Consider the earlier example where an auditor wishes to confirm if the
population contains less than five percent misstatement, suggesting the
hypotheses $H_1$: $\theta <$ 0.05 and $H_0$: $\theta \geq$ 0.05. They have
selected a sample of $n$ = 100 items, with $k$ = 1 item found to contain a
misstatement. The prior distribution is presumed to be a default beta(1,1)
prior. The subsequent call evaluates the sample using a Bayesian non-stratified
evaluation procedure [@stewart_2013; @derks_2021].

```{r}
evaluation(materiality = 0.05, x = 1, n = 100, method = "binomial", prior = TRUE)
```

The output indicates that the most likely misstatement in the population is
estimated to be $\frac{k}{n}$ = $\frac{1}{100}$ = 0.01, or 1 percent, and the
95 percent (one-sided) credible interval spans from 0 percent to 4.61 percent.
The minor discrepancy between the classical and default Bayesian results in
the upper limit can be attributed to the prior distribution, which needs to be
proper for the calculation of a Bayes factor. Classical results can be
replicated by formulating an improper prior distribution using
`method = "strict"` in the `auditPrior()` function. The Bayes factor in this
scenario is demonstrated to be $BF_{10}$ = 515, signifying that the sample data
are approximately 515 times more likely to occur under the hypothesis of
tolerable misstatement than under the hypothesis of material misstatement.

It is important to note that this is a considerably high Bayes factor given the
small amount of data observed. This can be explained by the fact that the Bayes
factor is influenced by the prior distribution for $\theta$. The default prior
distribution is **not** a good prior for hypothesis testing. As a general
guideline, when the prior distribution is extremely conservative in relation to
the hypothesis of tolerable misstatement (as with `method = 'default'`), the
Bayes factor tends to overstate the evidence supporting this hypothesis. This
dependency can be alleviated by employing a prior distribution that is impartial
towards the hypotheses [@derks_2022], which can be achieved using
`method = "impartial"` in the `auditPrior()` function.

```{r}
prior <- auditPrior(materiality = 0.05, method = "impartial", likelihood = "binomial")
evaluation(materiality = 0.05, x = 1, n = 100, prior = prior)
```

The output reveals that $BF_{10}$ = 47, suggesting that under the presumption of
impartiality, there is substantial evidence for $H_1$, the hypothesis that the
population contains misstatements less than five percent of the population
(tolerable misstatement). Given that both prior distributions resulted in
persuasive Bayes factors, the results can be deemed robust to the selection of
prior distribution. Consequently, the auditor can deduce that the sample
provides compelling evidence to conclude that the population does not contain
material misstatement.

### Stratified samples

In a stratified sampling method, the auditor extracts samples from various
subgroups, or strata, within a population. This could be applicable in a group
audit scenario where the audited organization comprises different components or
branches. Stratification becomes pertinent for the group auditor when they need
to form an opinion on the group as a whole, as they are required to consolidate
the samples taken by the component auditors.

For instance, consider the `retailer` data set included in the package. The
organization in question has twenty branches spread across the country. In each
of the twenty strata, a component auditor has conducted a statistical sample and
reported the results to the group auditor. 

```{r}
data("retailer")
print(retailer)
```

Generally, there are two methodologies for evaluating a stratified sample: no
pooling and partial pooling [see @derks_2022b]. When using the `evaluation()`
function in a stratified sampling context, you need to specify the type of
pooling to be used via its `pooling` argument. No pooling presumes no
similarities between strata, implying that all strata are analyzed
independently. Partial pooling presumes both differences and similarities
between strata, implying that information can be shared between strata. This
technique is also known as multilevel or hierarchical modeling and can lead to
more efficient population and stratum estimates. However, it is currently only
available in **jfa** when conducting a Bayesian analysis. For this reason, this
vignette primarily describes the Bayesian approach to evaluating stratified
audit samples. However, transitioning from a Bayesian approach to a classical
approach only requires setting `prior = FALSE`.

The number of units (this can be items or monetary units depending on the audit
objective) per stratum in the population can be supplied with `N.units` to weigh
the stratum estimates for determining the population estimate. This process is
known as poststratification. If `N.units` is not specified, it is assumed that
each stratum is equally represented in the population.

#### Approach 1: No pooling

The no pooling approach (`pooling = "none"`) is the default option and assumes
there are no similarities between strata. This implies that the prior
distribution, specified through `prior`, is applied independently in each
stratum. This approach allows for independent estimates of the misstatement in
each stratum, but for this reason it also results in a relatively high
uncertainty in the population estimate. The following command evaluates the
sample using a Bayesian stratified evaluation procedure, where the stratum
estimates are poststratified to derive the population estimate. Note that it is
important to set the seed via `set.seed()` because the posterior distribution is
determined via sampling.

```{r}
set.seed(1)
result_np <- evaluation(
  materiality = 0.05, method = "binomial",
  n = retailer[["samples"]], x = retailer[["errors"]],
  N.units = retailer[["items"]], pooling = "none",
  alternative = "two.sided", prior = TRUE
)
summary(result_np)
```

In this scenario, the output of the `summary()` function indicates that the
estimated misstatement in the population is 5.98 percent, with the 95 percent
(two-sided) credible interval extending from 4.28 percent to 8.22 percent. The
estimates for each stratum vary significantly from one another but exhibit
relative uncertainty. They can be visualized via the call below to
`plot(..., type = "estimates")`

```{r fig.align="center", fig.height=4, fig.width=6}
plot(result_np, type = "estimates")
```

The prior and posterior distribution for the population misstatement can be
obtained using the `plot(..., type = "posterior")` function.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(result_np, type = "posterior")
```

#### Approach 2: Partial pooling

```{r, include = FALSE}
options(mc.iterations = 10000, mc.warmup = 2000)
```

The partial pooling approach (`pooling = "partial"`) presumes both differences
and similarities between strata. This enables the auditor to share information
among the strata to minimize uncertainty in the population estimate. The
following call evaluates the sample using a Bayesian stratified evaluation
procedure, where the stratum estimates are poststratified to derive the
population estimate. Remember, it is important to set the seed via `set.seed()`
to make the results reproducible.

```{r}
set.seed(1)
result_pp <- evaluation(
  materiality = 0.05, method = "binomial",
  n = retailer[["samples"]], x = retailer[["errors"]],
  N.units = retailer[["items"]], pooling = "partial",
  alternative = "two.sided", prior = TRUE
)
summary(result_pp)
```

In this scenario, the output indicates that the estimated misstatement in the
population is 4.23 percent, with the 95 percent credible interval extending from
3.25 percent to 5.37 percent. Note that this population estimate is considerably
less uncertain compared to the no pooling approach. Similarly to the no pooling
approach, the stratum estimates differ from each other but are closer together
and exhibit less uncertainty. This can be explained by the fact that the partial
pooling approach allows for information to be shared between strata. The stratum
estimates can be visualized via a call to `plot(..., type = "estimates")`.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(result_pp, type = "estimates")
```

The prior and posterior distribution for the population misstatement can be
obtained using the `plot(..., type = "posterior")` function.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(result_pp, type = "posterior")
```

## Evaluation using data

In this example, we will demonstrate how to evaluate a stratified sample using a
data set. We will use the `allowances` data set that is included in the package.
This data set comprises $N$ = 3500 subsidy declarations from municipalities.
Each line item has a recorded value book value (column `bookValue`) and an
audited value (column `auditValue`), which is the true value for the purpose of
this illustration. The data set already identifies the items that have been
audited as part of the sample in the column `times`. In this scenario, we will
be performing estimation and therefore do not specify the `materiality` argument
in the `evaluation()` function.

```{r}
data("allowances")
head(allowances)
```

### Non-stratified samples

To evaluate a non-stratified sample using data, you need to specify the `data`,
`values`, and `values.audit` arguments. The input for these arguments should be
the name of the corresponding column in the input for the `data` argument.

#### Classical approach

The command below evaluates the `allowances` sample using a classical
non-stratified evaluation approach. Note that the sample is automatically
separated from the population because the `times` value for items not in the
sample is `0`.

```{r}
evaluation(
  data = allowances, times = "times", method = "binomial",
  values = "bookValue", values.audit = "auditValue"
)
```

In this instance, the output indicates that the estimated misstatement in the
population is 15.77 percent. The 95 percent (one-sided) confidence interval
extends from 0 percent to 17.34 percent. More detailed information can be
obtained via the `summary()` function.

#### Bayesian approach

The call below evaluates the `allowances` sample using a Bayesian non-stratified
evaluation procedure. The performance materiality for this example is set to
twenty percen of the population value.

```{r}
result <- evaluation(
  materiality = 0.2, data = allowances, times = "times", method = "binomial",
  values = "bookValue", values.audit = "auditValue", prior = TRUE
)
print(result)
```

The output shows that the estimate of the misstatement in the population is
15.77 percent, with the 95 percent (one-sided) credible interval ranging from 0
percent to 17.33 percent. More detailed information can be obtained via
`summary()` and the prior and posterior distribution can be obtained by a
call to `plot(..., type = "posterior")`.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(result, type = "posterior")
```

It is also possible to see how the Bayes factor evolves as a function of the
sample size. This can be done using `plot(..., type = "sequential")`. In this
case, the Bayes factor is very large due to the large sample.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(result, type = "sequential")
```

### Stratified samples

To evaluate a stratified sample using a data set, you need to specify the
`data`, `values`, `values.audit`, and `strata` arguments in the `evaluation()`
function. The input for `N.units` is once again optional. In this example, the
units are monetary, determined by summing up the book values of the items within
each stratum. For instance, we can see that stratum two is the largest, with
a total value of $2,792,814.33 and stratum five is the smallest, with a total
value of $96,660.53.

```{r}
N.units <- aggregate(allowances$bookValue, list(allowances$branch), sum)$x
print(data.frame(N.units))
```

#### Classical approach

The following command evaluates the `allowances` sample using a classical
stratified evaluation method. In this process, the estimates from each stratum
are poststratified to derive the estimate for the entire population. Note that
for computational reasons it is important to set a seed here via `set.seed()`.

```{r}
set.seed(1)
result <- evaluation(
  data = allowances, times = "times", method = "binomial",
  values = "bookValue", values.audit = "auditValue",
  N.units = N.units, strata = "branch",
  alternative = "two.sided"
)
print(result)
```

In this instance, the output reveals that the estimated misstatement in the
population is 14.72 percent. The 95 percent confidence interval spans from
12.98 percent to 17.6 percent. The precision of the population estimate is
therefore 4.26 percent. The estimates for each stratum are visualized below. For
more detailed information, including the actual stratum estimates, you can use
the `summary()` function.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(result, type = "estimates")
```

#### Bayesian approach

```{r, include = FALSE}
options(mc.iterations = 15000, mc.warmup = 5000)
```

Bayesian inference can enhance the estimates obtained from the classical
approach by pooling information across strata where feasible. The following
command evaluates the `allowances` sample using a Bayesian stratified evaluation
method. In this process, the estimates from each stratum are pooled and
poststratified to derive the estimate for the entire population.

```{r}
set.seed(1)
result <- evaluation(
  data = allowances, times = "times", method = "binomial",
  values = "bookValue", values.audit = "auditValue",
  N.units = N.units, strata = "branch", pooling = "partial",
  alternative = "two.sided",
  prior = TRUE
)
print(result)
```

The output indicates that the estimated misstatement in the population is
16.59 percent. The 95 percent credible interval spans from 15.71 percent to
17.57 percent. The precision of the population estimate is therefore 1.86
percent, which is lower than that of the classical approach. The estimates for
each stratum are visualized below using the `plot(..., type = "estimates)`
command but their actual values can be once again be obtained using the
`summary()` function.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(result, type = "estimates")
```

The prior and posterior distribution for the population misstatement can be
obtained via the `plot(..., type = "posterior")` function.

```{r fig.align="center", fig.height=4, fig.width=6}
plot(result, type = "posterior")
```

## References
<div id="refs"></div>
