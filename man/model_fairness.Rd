% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model_fairness.R
\name{model_fairness}
\alias{model_fairness}
\title{Algorithm Auditing: Fairness Metrics and Bias Detection}
\usage{
model_fairness(
  data,
  sensitive,
  target,
  predictions,
  reference = NULL,
  positive = NULL,
  materiality = 0.2,
  alternative = c("two.sided", "greater", "less"),
  conf.level = 0.95
)
}
\arguments{
\item{data}{The input data.}

\item{sensitive}{The column name indicating the sensitive variable.}

\item{target}{The column name indicating the target class labels.}

\item{predictions}{The column name indicating the predictions class labels.}

\item{reference}{The reference class for computing the fairness metrics.
If \code{NULL} (the default), the first level of the \code{sensitive}
column is used.}

\item{positive}{The positive class for computing the fairness metrics.
If \code{NULL} (the default), the first level of the \code{target}
column is used.}

\item{materiality}{The materiality value for determining fairness.}

\item{alternative}{The type of confidence interval to produce. Possible
options are \code{two.sided} (the default), \code{greater} and \code{less}.}

\item{conf.level}{a numeric value between 0 and 1 specifying the
confidence level (i.e., 1 - audit risk / detection risk).}
}
\value{
An object of class \code{jfaModelBias} containing:

\item{reference}{The reference group for computing the fairness metrics.}
\item{positive}{The positive class used in computing the fairness metrics.}
\item{alternative}{The type of confidence interval.}
\item{confusion.matrix}{A list of confusion matrices for each group.}
\item{performance}{A data frame containing performance metrics for each
  group, including accuracy, precision, recall, and F1 score.}
\item{fairness}{A data frame containing fairness metrics for each group,
  including demographic parity, proportional parity, predictive rate parity,
  accuracy parity, false negative rate parity, false positive rate parity,
  true positive rate parity, negative predicted value parity, and statistical
  parity.}
\item{ratio}{A data frame containing fairness ratios for each metric,
  comparing each group to the reference group.}
\item{materiality}{The materiality value used to determine the out of bounds
  metrics.}
\item{data.name}{The name of the input data object.}
}
\description{
This function detects bias in algorithmic decision-making
systems by computing various fairness metrics. It provides an assessment of
fairness across different groups based on the observed and predicted
outcomes. The function allows for evaluating fairness using metrics such as
demographic parity, proportional parity, predictive rate parity, accuracy
parity, false negative rate parity, false positive rate parity, true positive
rate parity, negative predicted value parity, and specificity parity and
decide whether groups are fair to a certain degree and within a certain
materiality threshold. Currently, it only supports binary classification.
}
\details{
The following fairness metrics are computed on the basis of the
  true positives (TP), false positives (FP), true negative (TN) and false
  negatives (FN) in the confusion matrix for each group.

\itemize{
  \item{Demographic parity: }{measures whether the observed variable is
    distributed equally across different groups, calculated as TP + FP.}
  \item{Proportional parity: }{measures whether the positive rate is
    distributed equally across different groups, calculated as (TP + FP) /
    (TP + FP + TN + FN).}
  \item{Predictive rate parity: }{measures whether the positive prediction rate
    is the same across different groups, calculated as TP / (TP + FP).}
  \item{Accuracy parity: }{measures whether the overall accuracy is the same
    across different groups, calculated as (TP + TN) / (TP + FP + TN + FN).}
  \item{False negative rate parity: }{measures whether the false negative rate
    is the same across different groups, calculated as FN / (FP + FN).}
  \item{False positive rate parity: }{measures whether the false positive rate
    is the same across different groups, calculated as FP / (TN + FP).}
  \item{True positive rate parity: }{measures whether the true positive rate is
    the same across different groups, calculated as TP / (TP + FN).}
  \item{Negative predicted value parity: }{measures whether the negative
    predicted value is the same across different groups, calculated as TN /
    (TN + FN).}
  \item{Specificity parity: }{measures whether the true positive rate
    is the same across different groups, calculated as TN / (TN + FP).}
}
}
\examples{
model_fairness(compas, "Ethnicity", "TwoYrRecidivism", "Predicted",
  reference = "Caucasian", positive = "yes"
)
}
\references{
Pessach, D. & Shmueli, E. (2022). A review on fairness in machine
  learning. \emph{ACM Computing Surveys}, 55(3), 1-44. \doi{10.1145/3494672}
}
\author{
Koen Derks, \email{k.derks@nyenrode.nl}
}
\keyword{algorithm}
\keyword{audit}
\keyword{bias}
\keyword{fairness}
\keyword{model}
\keyword{performance}
